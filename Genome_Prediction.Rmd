---
title: "Getting Started with Genomic Prediction"
author: "Julin Maloof"
date: "November 22, 2016"
output: 
  revealjs::revealjs_presentation:
    reveal_options:
      width: 1200
      height: 800
    incremental: true
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,cache = TRUE,autodep = TRUE)
```

```{r, include=FALSE}
library(bigRR)
library(ggplot2)
library(magrittr)
library(reshape2)
library(rrBLUP)
library(BGLR)
```

# Genomic Selection Intro

## Goal: Predictive Breeding
<!-- .slide: style="text-align: left;"> --> 

* Want to breed plants for better performance, resistance, etc.
* Use genetic / genomic data to predict best plants for breeding

## Old school: Marker assisted selection

* Use QTL or GWAS to find a few markers linked to trait of interest
* Genotype at those markers to "pyramid" during breeding
* Problem: ignores the many, many small loci that contribute to the trait

## Genomic Selection

* Instead of focusing on a few main loci, try to predict the effects of all loci
* QTL and GWAS fit a separate regression model for each location being considered
$ hyp \sim \beta1*M1 $
$ hyp \sim \beta2*M2 $
$ hyp \sim \beta3*M3 $
...
$ hyp \sim  \beta * M250000 $

* Genomic Selection fits a model to all markers simultaneously

$ hyp \sim \beta1*M1 + \beta2*M2 + \beta3*M3 + ... +\beta250000*M250000 $

## Genomic Selection

* Genomic Selection fits a model to all markers simultaneously

$ hyp \sim \beta1*M1 + \beta2*M2 + \beta3*M3 + ... +\beta250000*M250000 $

* Once this model is fit then we can predict the performance of other strains
* Challenge: How to fit a regression model with hundreds of thousands of predictors?

## Penalized Regression

* Standard regression models do not perform well with many predictors
* If we expect that most predictors will have an effect size of ~ 0 (we do in this case), use _penalized regression_
* Can be done using frequentist framework:
  * "Penalize" models for non-zero coefficients
  * Lasso Regression, Ridge Regression, Elastic Net
* Can be done using Bayesian framework:
  * Use priors strongly biased towards zero
  * Horseshoe, Laplace, Student's T, etc.
  
# Today's goal

## Tool exploration

* The KIAT project aims to use Genomic Selection techniques for predicitive breeding
* My goal was to start becoming familiar with the available tools in R
* Use hypocotyl data set from Filiault and Maloof (2012)
    * 169 Arabidopsis natural accessions
    * 250,000 SNPs
* Train on 120 and try to predict remaining 49
                              
```{r, include=FALSE}
## get the data

#Also center the genotpyes, so that the genotypes are represented as -1, 0, +1, as needed by some packages.

load("pheno.geno.Rdata")
geno.cols <- grep("^V",colnames(pheno.geno))
geno.center <- geno*2-1
head(geno.center[,1:10])
head(geno[,1:10])
all(row.names(geno.center) == row.names(pheno))
pheno <- as.data.frame(pheno)
```


# bigRR

Package bigRR (big Ridge Regression) uses optimized code to fit penalized Ridge Regression models.  
Enables separate shrinkage parameters to be used for each marker, in a two-step process

```{r, include=FALSE}
bigRR1 <- bigRR(y=pheno$high.RFR,
                X = matrix(1,nrow = nrow(pheno),ncol=1), # intercepts
                Z = geno.center)
bigRR1.update <- bigRR_update(bigRR1,Z = geno.center) #this allows heteroscedatic shrinkage (stronger shrinkage on SNPs than others).
```

## compare models with uniform and variable shrinkage

using all data.  Plot predicted marker effects

```{r, include=FALSE}
snpBlups <- data.frame(bigRR=bigRR1$u, bigRR.HME=bigRR1.update$u,index=1:nrow(bigRR1$u)) %>% melt(id.vars="index",variable.name="model")
head(snpBlups)
summary(snpBlups)
```

```{r, echo=FALSE}
snpBlups <- snpBlups[sample(nrow(snpBlups)),] #for a better plot (if not facetting), randomize the order of the observations
pl <- ggplot(snpBlups,aes(x=index,y=value,color=model))
pl <- pl + geom_point(size=.5,alpha=.5)
pl + facet_wrap(~ model)
```

## plot predicted versus actual (using all data)

```{r, echo=FALSE}
hyp.predict.wide <- data.frame(observed=pheno$high.RFR,
                          bigRR=bigRR1$beta + geno %*% bigRR1$u,
                          bigRR.HME=bigRR1.update$beta + geno %*% bigRR1.update$u) 
hyp.predict <-  melt(hyp.predict.wide,id.vars="observed",variable.name="model",value.name = "predicted")
pl <- ggplot(hyp.predict,aes(x=observed,y=predicted,color=model))
pl + geom_point() + ggtitle("two bigRR models, all data")
cor(hyp.predict.wide)
```
fits the model data well

## predict new observations

```{r, include=FALSE}
pheno.train.120 <- pheno[1:120,]
pheno.test.120 <- pheno[121:169,]
geno.train.120 <- geno.center[1:120,]
geno.test.120 <- geno.center[121:169,]
K.mat.train.120 <- K.mat[1:120,1:120]
bigRR.train1 <- bigRR(y=pheno.train.120$high.RFR,
                X = matrix(1,nrow = nrow(pheno.train.120),ncol=1), # intercepts
                Z = geno.train.120)
bigRR.train1.update <- bigRR_update(bigRR.train1,Z = geno.train.120) #this allows heteroscedatic shrinkage (stronger shrinkage on SNPs than others).
```

```{r, echo=FALSE}
hyp.predict.120.wide <- data.frame(observed=pheno.test.120$high.RFR,
                          bigRR=bigRR.train1$beta + geno.test.120 %*% bigRR.train1$u,
                          bigRR.HME=bigRR.train1.update$beta + geno.test.120 %*% bigRR.train1.update$u)
hyp.predict.120 <- melt(hyp.predict.120.wide,id.vars="observed",variable.name="model",value.name = "predicted")
pl <- ggplot(hyp.predict.120,aes(x=observed,y=predicted,color=model))
pl + geom_point() + ggtitle("two bigRR models, train on 120")

cor(hyp.predict.120.wide)
```

Better than nothing, but not as good as I hoped.  Try something else?

# rrBLUP

similar to bigRR, not included

```{r, eval=FALSE, include=FALSE} 
# not needed for this analysis
impute <- A.mat(geno.center,max.missing = .5, impute.method = "mean", return.imputed = TRUE,n.core=3)
geno_impute <- impute$imputed
any(apply(geno_impute,2,function(x) any(is.na(x)))) #check for NAs.  If there are any, then would need to remove NA columns
```

fit model
```{r, eval= FALSE, include=FALSE}
rrBLUP1 <- mixed.solve(pheno.train$high.RFR, Z=geno.train)
names(rrBLUP1)
rrBLUP1$beta
head(rrBLUP1$u)
```

predict from model
```{r, eval=FALSE, include=FALSE}
prediction <- rrBLUP1$beta[1] + geno.test %*% as.matrix(rrBLUP1$u)
cor(pheno.test$high.RFR,prediction)
plot(pheno.test$high.RFR,prediction)
```

# BGLR

BGLR is a package that implements many different Bayesian approached to genomics selection.

Two versions will be explored here
* Bayesian Lasso
* Bayes C

## Fit a Bayesian Lasso model

```{r, include=FALSE}
system.time(bglr.bl1 <- BGLR(y=pheno.train.120$high.RFR, 
                             ETA=list(list(X=geno.train.120,model="BL")),
                             verbose = FALSE,
                             saveAt = "bglr_output/bglr.bl1_",
                             nIter=12000,burnIn = 2000))
```

Fit a Bayesian Lasso model, with K

```{r, include=FALSE}
system.time(bglr.bl2 <- BGLR(y=pheno.train.120$high.RFR,
                             ETA=list(list(X=geno.train.120,model="BL"),
                                      list(K=K.mat.train.120,model="RKHS")),
                             verbose = FALSE,
                             saveAt = "bglr_output/bglr.bl2_",
                             nIter=12000,burnIn = 2000))
```

Fit a BayesC model with

```{r, include=FALSE}
system.time(bglr.bc1 <- BGLR(y=pheno.train.120$high.RFR, 
                             ETA=list(list(X=geno.train.120,model="BayesC")),
                             verbose = FALSE,
                             saveAt = "bglr_output/bglr.bc1_",
                             nIter=12000,burnIn = 2000))
```

Fit a BayesC model with K
```{r, include=FALSE}
system.time(bglr.bc2 <- BGLR(y=pheno.train.120$high.RFR,
                             ETA=list(list(X=geno.train.120,model="BayesC"),
                                      list(K=K.mat.train.120,model="RKHS")),
                             verbose = FALSE,
                             saveAt = "bglr_output/bglr.bc2_",
                             nIter=12000,burnIn = 2000))
```

```{r, eval=TRUE, include=FALSE}
save.image(file = "Genome_Prediction_Fits.Rdata")
```

```{r bglr_functions, include=FALSE}
plot_fitted_observed <- function(fit,title="fitted vs observed, training set") {
  print(qplot(pheno.train.120$high.RFR,fit$yHat,geom = "point",main = title,xlab="observed",ylab="fitted"))
  cor(pheno.train.120$high.RFR,fit$yHat)
}

plot_predicted_observed <- function(fit,title="predicted vs observed, test set") {
  prediction <- geno.test.120 %*% fit$ETA[[1]]$b + fit$mu
  print(qplot(pheno.test.120$high.RFR,prediction,xlab='observed',ylab='predicted',main=title,geom="point"))
  cor(prediction,pheno.test.120$high.RFR)
}
```

## Bayesian Lasso, no structure

```{r}
plot_fitted_observed(bglr.bl1)
plot_predicted_observed(bglr.bl1)
```

## Bayesian Lasso, with structure

```{r}
plot_fitted_observed(bglr.bl2)
plot_predicted_observed(bglr.bl2)
```

## BayesC, no structure

```{r}
plot_fitted_observed(bglr.bc1)
plot_predicted_observed(bglr.bc1)
```

## BayesC, with structure

```{r}
plot_fitted_observed(bglr.bc2)
plot_predicted_observed(bglr.bc2)
```


```{r, eval=FALSE, echo=FALSE}
#1# Estimated Marker Effects & posterior SDs
bHat <- bglr.bl1$ETA[[1]]$b
SD.bHat <- bglr.bl1$ETA[[1]]$SD.b
plot(bHat, ylab='Estimated Marker Effect',
type='p',cex=.5,col=4,main='Marker Effects')

#2# Predictions
  # Total prediction
yHat<-bglr.bl1$yHat
tmp<-range(c(pheno.train.120$high.RFR,yHat))
plot(yHat~pheno.train.120$high.RFR,xlab='Observed',ylab='Predicted',col=2,
            xlim=tmp,ylim=tmp); abline(a=0,b=1,col=4,lwd=2)

# predict for the test set
prediction <- geno.test.120 %*% bglr.bl1$ETA[[1]]$b + bglr.bl1$mu
plot(prediction~pheno.test.120$high.RFR,xlab='Observed',
ylab='Predicted',col=2)
cor(prediction,pheno.test.120$high.RFR)

#3# Goodness of fit and related statistics
   bglr.bl1$fit
   blgr.bl1$varE # compare to var(y)

#4# Trace plots
  list.files()
# Residual variance
varE<-scan('varE.dat') 
plot(varE,type='o',col=2,cex=.5,ylab=expression(var[e])); abline(h=bglr.bl1$varE,col=4,lwd=2); abline(v=bglr.bl1$burnIn/bglr.bl1$thin,col=4)
# lambda (regularization parameter of the Bayesian Lasso)
lambda<-scan('ETA_1_lambda.dat')
plot(lambda,type='o',col=2,cex=.5,ylab=expression(lambda)); abline(h=bglr.bl1$ETA[[1]]$lambda,col=4,lwd=2); abline(v=bglr.bl1$burnIn/bglr.bl1$thin,col=4)
```

# To Do

* pull different test and training sets
* Check BGLR convergence
* Compare to traditional GWAS
    * Marker effects
    * Predictions
