---
title: "Getting Started with Genomic Prediction"
author: "Julin Maloof"
date: "November 22, 2016"
output: 
ioslides_presentation:
widescreen: true
incremental: true
fig_width: 6
fig_height: 4
fig_caption: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,cache = TRUE,autodep = TRUE,eval=FALSE)
```

```{r, include=FALSE, eval=TRUE, cache=FALSE}
library(bigRR)
library(ggplot2)
library(magrittr)
library(reshape2)
library(rrBLUP)
library(BGLR)
load("Genome_Prediction_Fits.Rdata")
```

## RMarkdown presentation

This presentation made in R Markdown.

The file is available at:

https://github.com/jnmaloof/Hypocotyl_Genomic_Selection

# Genomic Selection Intro

## Goal: Predictive Breeding

* Want to breed plants for better performance, resistance, etc.
* Use genetic / genomic data to predict best plants for breeding

## Old school: Marker assisted selection

* Use QTL or GWAS to find markers linked to trait of interest
* Genotype at those markers to "pyramid" during breeding
* Problem: ignores the many, many small loci that contribute to the trait

## Genomic Selection {.build}

* Instead of focusing on a few main loci, try to predict the effects of all loci
* QTL and GWAS fit a separate regression model for each location being considered

$hyp \sim \beta1*M1$

$hyp \sim \beta2*M2$

$hyp \sim \beta3*M3$

...

$hyp \sim  \beta * M250000$

* Genomic Selection fits a model to all markers simultaneously

$hyp \sim \beta1*M1 + \beta2*M2 + \beta3*M3 + ... +\beta250000*M250000$

## Genomic Selection

* Genomic Selection fits a model to all markers simultaneously

$hyp \sim \beta1*M1 + \beta2*M2 + \beta3*M3 + ... +\beta250000*M250000$

* Once this model is fit then we can predict the performance of other strains
* Challenge: How to fit a regression model with hundreds of thousands of predictors?

## Penalized Regression

* Standard regression models do not perform well with many predictors
* If we expect that most predictors will have an effect size of ~ 0 (we do in this case), use _penalized regression_
* Can be done using frequentist framework:
* "Penalize" models for non-zero coefficients
* Lasso Regression, Ridge Regression, Elastic Net
* Can be done using Bayesian framework:
* Use priors strongly biased towards zero
* Horseshoe, Laplace, Student's T, etc.

# Today's goal

## Tool exploration

* The KIAT project aims to use Genomic Selection techniques for predicitive breeding
* My goal was to start becoming familiar with the available tools in R
* Use hypocotyl data set from Filiault and Maloof (2012)
* 169 Arabidopsis natural accessions
* 250,000 SNPs
* Train on 120 and try to predict remaining 49

```{r, include=FALSE}
## get the data

#Also center the genotpyes, so that the genotypes are represented as -1, 0, +1, as needed by some packages.

load("pheno.geno.Rdata")
geno.cols <- grep("^V",colnames(pheno.geno))
geno.center <- geno*2-1
head(geno.center[,1:10])
head(geno[,1:10])
all(row.names(geno.center) == row.names(pheno))
pheno <- as.data.frame(pheno)
```


# bigRR

## bigRR

* Package bigRR (big Ridge Regression) uses optimized code to fit penalized Ridge Regression models.  
* Enables separate shrinkage parameters to be used for each marker, in a two-step process

```{r, include=FALSE}
bigRR1 <- bigRR(y=pheno$high.RFR,
                X = matrix(1,nrow = nrow(pheno),ncol=1), # intercepts
                Z = geno.center)
bigRR1.update <- bigRR_update(bigRR1,Z = geno.center) #this allows heteroscedatic shrinkage (stronger shrinkage on SNPs than others).
```

## compare models with uniform and variable shrinkage

using all data.  Plot predicted marker effects

```{r, include=FALSE}
snpBlups <- data.frame(bigRR=bigRR1$u, bigRR.HME=bigRR1.update$u,index=1:nrow(bigRR1$u)) %>% melt(id.vars="index",variable.name="model")
head(snpBlups)
summary(snpBlups)
```

```{r, echo=FALSE, eval=TRUE}
snpBlups <- snpBlups[sample(nrow(snpBlups)),] #for a better plot (if not facetting), randomize the order of the observations
pl <- ggplot(snpBlups,aes(x=index,y=value,color=model))
pl <- pl + geom_point(size=.5,alpha=.5)
pl + facet_wrap(~ model)
```

## plot predicted versus actual (using all data)

```{r, echo=FALSE, eval=TRUE}
hyp.predict.wide <- data.frame(observed=pheno$high.RFR,
                               bigRR=bigRR1$beta + geno %*% bigRR1$u,
                               bigRR.HME=bigRR1.update$beta + geno %*% bigRR1.update$u) 
hyp.predict <-  melt(hyp.predict.wide,id.vars="observed",variable.name="model",value.name = "predicted")
pl <- ggplot(hyp.predict,aes(x=observed,y=predicted,color=model))
pl + geom_point() + ggtitle("two bigRR models, all data")
cor(hyp.predict.wide)
```
fits the model data well

## predict new observations

```{r, include=FALSE}
pheno.train.120 <- pheno[1:120,]
pheno.test.120 <- pheno[121:169,]
geno.train.120 <- geno.center[1:120,]
geno.test.120 <- geno.center[121:169,]
K.mat.train.120 <- K.mat[1:120,1:120]
bigRR.train1 <- bigRR(y=pheno.train.120$high.RFR,
                      X = matrix(1,nrow = nrow(pheno.train.120),ncol=1), # intercepts
                      Z = geno.train.120)
bigRR.train1.update <- bigRR_update(bigRR.train1,Z = geno.train.120) #this allows heteroscedatic shrinkage (stronger shrinkage on SNPs than others).
```

```{r, echo=FALSE, eval=TRUE}
hyp.predict.120.wide <- data.frame(observed=pheno.test.120$high.RFR,
                                   bigRR=bigRR.train1$beta + geno.test.120 %*% bigRR.train1$u,
                                   bigRR.HME=bigRR.train1.update$beta + geno.test.120 %*% bigRR.train1.update$u)
hyp.predict.120 <- melt(hyp.predict.120.wide,id.vars="observed",variable.name="model",value.name = "predicted")
pl <- ggplot(hyp.predict.120,aes(x=observed,y=predicted,color=model))
pl + geom_point() + ggtitle("two bigRR models, train on 120")

cor(hyp.predict.120.wide)
```

Better than nothing, but not as good as I hoped.  Try something else?

# rrBLUP

## rrBLUP
similar to bigRR, not included

```{r, eval=FALSE, include=FALSE} 
# not needed for this analysis
impute <- A.mat(geno.center,max.missing = .5, impute.method = "mean", return.imputed = TRUE,n.core=3)
geno_impute <- impute$imputed
any(apply(geno_impute,2,function(x) any(is.na(x)))) #check for NAs.  If there are any, then would need to remove NA columns
```

fit model
```{r, eval= FALSE, include=FALSE}
rrBLUP1 <- mixed.solve(pheno.train$high.RFR, Z=geno.train)
names(rrBLUP1)
rrBLUP1$beta
head(rrBLUP1$u)
```

predict from model
```{r, eval=FALSE, include=FALSE}
prediction <- rrBLUP1$beta[1] + geno.test %*% as.matrix(rrBLUP1$u)
cor(pheno.test$high.RFR,prediction)
plot(pheno.test$high.RFR,prediction)
```

# BGLR

## BGLR 

BGLR is a package that implements many different Bayesian approached to genomics selection.

Two versions will be explored here
* Bayesian Lasso
* Bayes C

Will fit with and without a population structure correction, K

```{r, include=FALSE}
system.time(bglr.bl1 <- BGLR(y=pheno.train.120$high.RFR, 
                             ETA=list(list(X=geno.train.120,model="BL")),
                             verbose = FALSE,
                             saveAt = "bglr_output/bglr.bl1_",
                             nIter=12000,burnIn = 2000))
```

Fit a Bayesian Lasso model, with K

```{r, include=FALSE}
system.time(bglr.bl2 <- BGLR(y=pheno.train.120$high.RFR,
                             ETA=list(list(X=geno.train.120,model="BL"),
                                      list(K=K.mat.train.120,model="RKHS")),
                             verbose = FALSE,
                             R2=.75,
                             saveAt = "bglr_output/bglr.bl2.R2.75_",
                             nIter=12000,burnIn = 2000))
```

Fit a BayesC model with

```{r, include=FALSE}
system.time(bglr.bc1 <- BGLR(y=pheno.train.120$high.RFR, 
                             ETA=list(list(X=geno.train.120,model="BayesC")),
                             verbose = FALSE,
                             saveAt = "bglr_output/bglr.bc1_",
                             nIter=12000,burnIn = 2000))
```

Fit a BayesC model with K
```{r, include=FALSE}
system.time(bglr.bc2 <- BGLR(y=pheno.train.120$high.RFR,
                             ETA=list(list(X=geno.train.120,model="BayesC"),
                                      list(K=K.mat.train.120,model="RKHS")),
                             verbose = FALSE,
                             saveAt = "bglr_output/bglr.bc2_",
                             nIter=12000,burnIn = 2000))
```

```{r, eval=FALSE, include=FALSE}
save.image(file = "Genome_Prediction_Fits.Rdata")
```

```{r bglr_functions, include=FALSE, eval=TRUE}
plot_fitted_observed <- function(fit,title="fitted vs observed, training set") {
  print(qplot(pheno.train.120$high.RFR,fit$yHat,geom = "point",main = title,xlab="observed",ylab="fitted"))
  c(cor(pheno.train.120$high.RFR,fit$yHat),cor(pheno.train.120$high.RFR,fit$yHat,method="kendall"))
}

plot_predicted_observed <- function(fit,title="predicted vs observed, test set") {
  prediction <- geno.test.120 %*% fit$ETA[[1]]$b + fit$mu
  print(qplot(pheno.test.120$high.RFR,prediction,xlab='observed',ylab='predicted',main=title,geom="point"))
  c(cor(prediction,pheno.test.120$high.RFR),cor(prediction,pheno.test.120$high.RFR,method = "kendall"))
}
```

## Bayesian Lasso, no structure, fit

```{r, eval=TRUE, echo=FALSE}
plot_fitted_observed(bglr.bl1)
```

## Bayesian Lasso, no structure, predict

```{r, eval= TRUE, echo=FALSE}
plot_predicted_observed(bglr.bl1)
```

## Bayesian Lasso, with structure, fit

```{r, eval=TRUE, echo=FALSE}
plot_fitted_observed(bglr.bl2)
```

## Bayesian Lasso, with structure, predict

```{r, eval=TRUE, echo=FALSE}
plot_predicted_observed(bglr.bl2)
```

## BayesC, no structure, fit

```{r, eval=TRUE, echo=FALSE}
plot_fitted_observed(bglr.bc1)
```

## BayesC, no structure, predict

```{r, eval=TRUE, echo=FALSE}
plot_predicted_observed(bglr.bc1)
```

## BayesC, with structure, fit

```{r, eval=TRUE, echo=FALSE}
plot_fitted_observed(bglr.bc2)
```

## BayesC, with structure, predict

```{r, eval=TRUE, echo=FALSE}
plot_predicted_observed(bglr.bc2)
```

```{r,eval=FALSE,echo=FALSE}
#3# Goodness of fit and related statistics
bglr.bl1$fit
blgr.bl1$varE # compare to var(y)

#4# Trace plots
list.files("bglr_output")
# Residual variance
varE<-scan('varE.dat') 
plot(varE,type='o',col=2,cex=.5,ylab=expression(var[e])); abline(h=bglr.bl1$varE,col=4,lwd=2); abline(v=bglr.bl1$burnIn/bglr.bl1$thin,col=4)
# lambda (regularization parameter of the Bayesian Lasso)
lambda<-scan('ETA_1_lambda.dat')
plot(lambda,type='o',col=2,cex=.5,ylab=expression(lambda)); abline(h=bglr.bl1$ETA[[1]]$lambda,col=4,lwd=2); abline(v=bglr.bl1$burnIn/bglr.bl1$thin,col=4)
```

Residual Variance
```{r}
varE.files <- dir("bglr_output",pattern="varE.dat",full.names = TRUE)
for (f in varE.files) {
  tmp.varE <- scan(f)
  plot(tmp.varE,type='l',col=2,cex=.5,ylab=expression(var[e]),main=basename(f))
  abline(h=bglr.bl1$varE,col=4,lwd=2); abline(v=bglr.bl1$burnIn/bglr.bl1$thin,col=4)
}
```
These are clearly autcorrelatd and mixing that well...

# To Do

## To do

* pull different test and training sets
* Check BGLR convergence
* Compare to traditional GWAS
* Marker effects
* Predictions
* Crosses

# multiple test and training sets

## multiple test and training sets

pull training and test sets at random and check performance both of bigRR and BGLR

first create lists of random train and test sets.  training size is 120

```{r}
n.trials <- 100
train.list <- lapply(1:n.trials,function(x) sample(1:nrow(pheno),size = 120, replace = FALSE))
test.list <- lapply(train.list, function(x) setdiff(1:nrow(pheno),x))
```

## run bigRR and record correlations

```{r}
bigRR.120.100trials <- sapply(1:n.trials,function(trial) {
  bigRR.train.tmp <- bigRR(y=pheno$high.RFR[train.list[[trial]]],
                           X = matrix(1,nrow = length(train.list[[trial]]),ncol=1), # intercepts
                           Z = geno[train.list[[trial]],])
  bigRR.train.tmp.update <- bigRR_update(bigRR.train.tmp,Z =  geno[train.list[[trial]],]) 
  tmp.predict <- data.frame(observed=pheno$high.RFR[test.list[[trial]]],
                            predicted=bigRR.train.tmp.update$beta + geno[test.list[[trial]],] %*% bigRR.train.tmp.update$u)
  c(Pearson=cor(tmp.predict)[1,2],Kendall=cor(tmp.predict,method="kendall")[1,2])
})
save.image(file = "Genome_Prediction_Fits.Rdata")
summary(t(bigRR.120.100trials))
```

## Bayesian Lasso Loop

```{r, eval=FALSE}
library(snowfall)
sfInit(cpus = 2)
bglr.bl.120.100trials <- sfApply(1:n.trials,function(trial) {
  
  bl.tmp <-  BGLR(y=pheno$high.RFR[train.list[[trial]]],
                  ETA=list(list(X=geno[train.list[[trial]],],model="BL"),
                           list(K=K.mat[train.list[[trial]],train.list[[trial]]],model="RKHS")),
                  verbose = FALSE,
                  nIter=5000,burnIn = 1000)
  prediction <- geno[test.list[[trial]],] %*% bl.tmp$ETA[[1]]$b + bl.tmp$mu
  
  c(Pearson=cor(prediction,pheno.test.120$high.RFR)[1,2],Kendall=cor(prediction,pheno.test.120$high.RFR,method = "kendall")[1,2])
  save.image(file = "Genome_Prediction_Fits.Rdata")
})
summary(bglr.bl.120.100trials)
```


## BayesC Loop

```{r, eval=FALSE}
library(snowfall)
sfInit(parallel=TRUE,cpus = 2)
sfLibrary(BGLR)
sfExport("n.trials","test.list","train.list","geno","pheno","K.mat")
bglr.bc.120.100trials <- sfSapply(1:n.trials,function(trial) {
  print(trial)
  
  bl.tmp <-  BGLR(y=pheno$high.RFR[train.list[[trial]]],
                  ETA=list(list(X=geno[train.list[[trial]],],model="BayesC"),
                           list(K=K.mat[train.list[[trial]],train.list[[trial]]],model="RKHS")),
                  verbose = FALSE,
                  nIter=5000,burnIn = 1000)
  tmp.predict <- data.frame(observed=pheno$high.RFR[test.list[[trial]]],
                            predicted=geno[test.list[[trial]],] %*% bl.tmp$ETA[[1]]$b + bl.tmp$mu)
  
  c(Pearson=cor(tmp.predict)[1,2],Kendall=cor(tmp.predict,method="kendall")[1,2])
})
save.image(file = "Genome_Prediction_Fits.Rdata")
summary(t(bglr.bc.120.100trials))
```

```{r}
plot(bigRR.120.100trials["Pearson",],bglr.bc.120.100trials["Pearson",])
```

## Next

Effect of training size (should keep test size the same)


